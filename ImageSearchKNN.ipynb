{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Challenge: Build a large-scale image search engine!\n",
    "\n",
    "You and your team of **three Cornell Tech students** are surely on the path to fame and fortune! You have been recruited by Google to disrupt Google Image Search by building a better search engine using novel statistical learning techniques.\n",
    "\n",
    "The specifications are simple: We need a way to **search for relevant images** given a natural language query. For instance, if a user types \"dog jumping to catch frisbee,\" your system will **rank-order the most relevant images** from a large database.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**During training**, you have a dataset of 10,000 samples. \n",
    "\n",
    "Each sample has the following data available for learning:\n",
    "- A 224x224 JPG image.\n",
    "- A list of tags indicating objects appeared in the image.\n",
    "- Feature vectors extracted using [Resnet](https://arxiv.org/abs/1512.03385), a state-of-the-art Deep-learned CNN (You don't have to train or run ResNet -- we are providing the features for you). See [here](http://ethereon.github.io/netscope/#/gist/b21e2aae116dc1ac7b50) for the illustration of the ResNet-101 architecture. The features are extracted from pool5 and fc1000 layer.\n",
    "- A five-sentence description, used to train your search engine.\n",
    "\n",
    "**During testing**, your system matches a single five-sentence description against a pool of 2,000 candidate samples from the test set. \n",
    "\n",
    "Each sample has:\n",
    "- A 224x224 JPEG image.\n",
    "- A list of tags for that image.\n",
    "- ResNet feature vectors for that image.\n",
    "\n",
    "**Output**:\n",
    "For each description, your system must rank-score each testing image with the likelihood of that image matches the given sentence. Your system then returns the name of the top 20 relevant images, delimited by space. See \"sample_submission.csv\" on the data page for more details on the output format.\n",
    "\n",
    "**Evaluation metric**:\n",
    "There are 2,000 descriptions, and for each description, you must compare against the entire 2,000-image test set. That is, rank-order test images for each test description. We will use **MAP@20** as the evaluation metric. If the corresponding image of a description is among your algorithm's 20 highest scoring images, this metric gives you a certain score based on the ranking of the corresponding image. Please refer to the evaluation page for more details. Use all of your skills, tools, and experience. It is OK to use libraries like numpy, scikit-learn, pandas, etc., as long as you cite them. Use cross-validation on training set to debug your algorithm. Submit your results to the Kaggle leaderboard and send your complete writeup to CMS. The data you use --- and the way you use the data --- is completely up to you.\n",
    "\n",
    "**Note**:\n",
    "The best teams of **three Cornell Tech students** might use visualization techniques for debugging (e.g., show top images retrieved by your algorithm and see whether they make sense or not), preprocessing, a nice way to compare tags and descriptions, leveraging visual features and combining them with tags and descriptions, supervised and/or unsupervised learning to best understand how to best take advantage of each data source available to them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File descriptions**:\n",
    "\n",
    "- images_train - 10,000 training images of size 224x224.\n",
    "- images_test - 2,000 test images of size 224x224.\n",
    "- tags_train - image tags correspond to training images. Each image have several tags indicating the human-labeled object categories appear in the image, in the form of \"supercategory:category\".\n",
    "- tags_test - image tags correspond to test images. Each image have several tags indicating the human-labeled object categories appear in the image, in the form of \"supercategory:category\".\n",
    "features_train - features extracted from a pre-trained Residual Network (ResNet) on training set, including 1,000 dimensional feature from classification layer (fc1000) and 2,048 dimensional feature from final convolution layer (pool5). Each dimension of the fc1000 feature corresponds to a WordNet synset here.\n",
    "- features_test - features extracted from the same Residual Network (ResNet) on test set, including 1,000 dimensional feature from classification layer (fc1000) and 2,048 dimensional feature from final convolution layer (pool5).\n",
    "- descriptions_train - image descriptions correspond to training images. Each image have 5 sentences for describing the image content.\n",
    "- descriptions_test - image descriptions for test images. Each image have 5 sentences for describing the image content. Notice that one test description corresponds to one test image. The task you need to do is to return top 20 images in test set for each test description.\n",
    "- sample_submission.csv - a sample submission file in the correct format.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import nltk\n",
    "import scipy\n",
    "import gensim\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for training/testing data\n",
    "my_path = os.getcwd()\n",
    "tags_train_path = os.path.join(my_path, 'tags_train')\n",
    "tags_test_path  = os.path.join(my_path, 'tags_test')\n",
    "desc_train_path = os.path.join(my_path, 'descriptions_train')\n",
    "desc_test_path  = os.path.join(my_path, 'descriptions_test')\n",
    "image_train_path = os.path.join(my_path, 'images_train')\n",
    "image_test_path  = os.path.join(my_path, 'images_test')\n",
    "features_train_res_path = os.path.join(my_path, 'features_train/features_resnet1000_train.csv')\n",
    "features_test_res_path  = os.path.join(my_path, 'features_test/features_resnet1000_test.csv')\n",
    "features_train_res_int_path = os.path.join(my_path, 'features_train/features_resnet1000intermediate_train.csv')\n",
    "features_test_res_int_path  = os.path.join(my_path, 'features_test/features_resnet1000intermediate_test.csv')\n",
    "\n",
    "# Sort files in ascending order\n",
    "def order_keys(text):\n",
    "    return int(text.split('.')[0])\n",
    "\n",
    "# Read/return list of images within a folder\n",
    "def read_images(folder_path):\n",
    "    images = []\n",
    "    image_files = os.listdir(folder_path)\n",
    "    image_files.sort(key = order_keys)\n",
    "    for image_file in image_files:\n",
    "        # Open each image file\n",
    "        im = Image.open(os.path.join(folder_path, image_file), 'r')\n",
    "        # Convert to an np array\n",
    "        images.append(np.asarray(im))\n",
    "        # Close the file\n",
    "        im.close()\n",
    "    return images\n",
    "\n",
    "# Read/return list of strings from files within a folder\n",
    "def read_strings(folder_path):\n",
    "    elements = []\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key = order_keys)\n",
    "    for f in files:\n",
    "        # Open each text file. Strip leading/trailing whitespace\n",
    "        lines = [line.strip() for line in open(os.path.join(folder_path, f))]\n",
    "        elements.append(' '.join(lines))\n",
    "    return elements\n",
    "\n",
    "# Read/return list of tags from files within a folder\n",
    "def read_tags(folder_path):\n",
    "    elements = []\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key = order_keys)\n",
    "    for f in files:\n",
    "        # Open each text file. Strip leading/trailing whitespace\n",
    "        lines = [line.strip() for line in open(os.path.join(folder_path, f))]\n",
    "        tags  = [line.split(':') for line in lines]\n",
    "        tags  = [item for sublist in tags for item in sublist]\n",
    "        elements.append(tags)\n",
    "    return elements\n",
    "\n",
    "# Read/return list of features\n",
    "def read_features(file_path):\n",
    "    reader = csv.reader(open(file_path), delimiter=\",\")\n",
    "    features = sorted(reader, key = lambda row: int(row[0].split('/')[1].split('.')[0]))\n",
    "    # Skip the image name\n",
    "    for ind, image in enumerate(features):\n",
    "        feats = [float(i) for i in image[1:]]\n",
    "        features[ind] = feats\n",
    "    return features\n",
    "\n",
    "# Transform input to lowercase\n",
    "def to_lowercase(sent):\n",
    "    return sent.lower()\n",
    "\n",
    "# OLD - Lemmatize input\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# def lemmatize(sent):\n",
    "#     words = sent.split(' ')\n",
    "#     lemmed_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "#     return ' '.join(lemmed_words)\n",
    "\n",
    "# OLD - Stem input\n",
    "# stemmer = SnowballStemmer('english')\n",
    "# def stem(sent):\n",
    "#     words = sent.split(' ')\n",
    "#     stemmed_words = [stemmer.stem(word) for word in words]\n",
    "#     return ' '.join(stemmed_words)\n",
    "    \n",
    "# OLD - Remove stop words from input\n",
    "def remove_stopwords(sent):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = sent.split(' ')\n",
    "    unstopped_words = [word for word in words if not word in stops]\n",
    "    return ' '.join(unstopped_words)\n",
    "\n",
    "# Remove special characters from input\n",
    "def remove_special_chars(sent):\n",
    "    unspecial_words = []\n",
    "    words = sent.split(' ')\n",
    "    for word in words:\n",
    "        unspecial_word = ''.join(char for char in word if char.isalnum())\n",
    "        unspecial_words.append(unspecial_word)\n",
    "    return ' '.join(unspecial_words)\n",
    "\n",
    "# Fit with count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "def count_vectorize_fit(corpus):\n",
    "    vectorizer.fit(corpus)\n",
    "\n",
    "# Perform counter vectorization\n",
    "def count_vectorize(corpus):\n",
    "    features = []\n",
    "    count_vects = vectorizer.transform(corpus)\n",
    "    count_vects = count_vects.toarray()\n",
    "    for vects in count_vects:\n",
    "        counts = [float(i) for i in vects]\n",
    "        features.append(counts)\n",
    "    return features\n",
    "\n",
    "# ALT - Fit with count vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "def tfid_vectorize_fit(corpus):\n",
    "    tfidf.fit(corpus)\n",
    "    \n",
    "# ALT - Perform TFID vectorization\n",
    "def tfid_vectorize(corpus):\n",
    "    features = []\n",
    "    count_vects = tfidf.transform(corpus)\n",
    "    count_vects = count_vects.toarray()\n",
    "    for vects in count_vects:\n",
    "        counts = [float(i) for i in vects]\n",
    "        features.append(counts)\n",
    "    return features\n",
    "\n",
    "# OLD - Normalize with magnitude\n",
    "def get_norm(sent):\n",
    "    return np.divide(sent, np.linalg.norm(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the training data\n",
    "X_tags   = read_tags(tags_train_path)\n",
    "X_images = read_images(image_train_path)\n",
    "X_descs  = read_strings(desc_train_path)\n",
    "X_feats  = read_features(features_train_res_path)\n",
    "X_feats_int = read_features(features_train_res_int_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training descriptions\n",
    "for index in range(len(X_descs)):\n",
    "    X_descs[index] = to_lowercase(X_descs[index])\n",
    "    X_descs[index] = remove_special_chars(X_descs[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFID the description data\n",
    "tfid_vectorize_fit(X_descs)\n",
    "X_descs_vect = tfid_vectorize(X_descs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Format the training data. \n",
    "# # We will combine each resnet feature vector with the correct corresponding normalized vector count\n",
    "# # and label that as 1. We will then combine the same resnet feature vector with a different normalized\n",
    "# # vector count and label that as 0. In this way, we are providing the NN with what we consider to be \n",
    "# # correct (1) or incorrect (0) values. For each resent feature vector, we will provide 1 correct and\n",
    "# # 2 incorrect values.\n",
    "# X_training_vals   = []\n",
    "# X_training_labels = []\n",
    "\n",
    "# for index, img_feat in enumerate(X_feats):\n",
    "#     # Add the correct resnet feature vector and vector count\n",
    "#     X_training_vals.append(np.append(X_descs_vect[index], img_feat))\n",
    "#     X_training_labels.append(1)\n",
    "    \n",
    "#     for i in range(20):\n",
    "#         # Choose random index other than the correct one\n",
    "#         rand_index = random.randrange(0, len(X_feats))\n",
    "#         while (rand_index == index):\n",
    "#             rand_index = random.randrange(0, len(X_feats))\n",
    "\n",
    "#         # Add the incorrect resnet feature vector and vector count\n",
    "#         X_training_vals.append(np.append(X_descs_vect[rand_index], X_feats[rand_index]))\n",
    "#         X_training_labels.append(0)\n",
    "\n",
    "# X_train = pd.DataFrame(X_training_vals, X_training_labels)\n",
    "# X_train = shuffle(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit KNN model - Regression\n",
    "knn = KNeighborsRegressor(n_neighbors = 15)\n",
    "knn.fit(X_descs_vect, X_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit KNN model - Classification\n",
    "# knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "# knn.fit(X_train.values, X_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the testing data\n",
    "X_tags_test   = read_tags(tags_test_path)\n",
    "X_images_test = read_images(image_test_path)\n",
    "X_descs_test  = read_strings(desc_test_path)\n",
    "X_feats_test  = read_features(features_test_res_path)\n",
    "X_feats_int_test = read_features(features_test_res_int_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the testing descriptions\n",
    "for index in range(len(X_descs_test)):\n",
    "    X_descs_test[index] = to_lowercase(X_descs_test[index])\n",
    "    X_descs_test[index] = remove_special_chars(X_descs_test[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFID the description data\n",
    "X_descs_vect_test = tfid_vectorize(X_descs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with testing data\n",
    "result_images = knn.predict(X_descs_vect_test)\n",
    "\n",
    "# Get matrix of distances between matching features\n",
    "feat_dist = scipy.spatial.distance.cdist(X_feats_test, result_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the outputs to CSV - Regression\n",
    "with open('test_results.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    writer.writerow(['Descritpion_ID','Top_20_Image_IDs'])\n",
    "\n",
    "    for index, dist in enumerate(feat_dist):\n",
    "        file_names = []\n",
    "        sorted_results = np.argsort(dist)\n",
    "        results = sorted_results[:20]\n",
    "\n",
    "        # Convert results to a string\n",
    "        for res in results:\n",
    "            file_names.append(str(res) + '.jpg')\n",
    "\n",
    "        # Write results to file\n",
    "        writer.writerow([str(index) + '.txt',' '.join(file_names)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run the model with testing data and write the outputs to CSV - Classification\n",
    "# with open('test_results.csv', 'w') as csvfile:\n",
    "#     writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "#     writer.writerow(['Description','Top_20_Image_IDs'])\n",
    "\n",
    "#     # Compare each description to each resnet feature\n",
    "#     for ind_outer, desc in enumerate(X_descs_vect_test):\n",
    "        \n",
    "#         indices = []\n",
    "#         file_names = []\n",
    "#         testing_vals = []\n",
    "\n",
    "#         for ind_inner, feature in enumerate(X_feats_test):\n",
    "#             indices.append(ind_inner)\n",
    "#             testing_vals.append(np.append(desc, feature))\n",
    "        \n",
    "#         # Predict\n",
    "#         results_prob = knn.predict_proba(testing_vals)\n",
    "#         results_pred = knn.predict(testing_vals)\n",
    "#         results_class_1, results_class_2 = zip(*results_prob)\n",
    "#         results = zip(indices, results_pred, results_class_1, results_class_2)\n",
    "\n",
    "#         print results\n",
    "        \n",
    "#         # Sort results by positive matches\n",
    "#         sorted_results = sorted(results, key=lambda tup: tup[2])\n",
    "            \n",
    "#         # Convert results to a string\n",
    "#         for res in sorted_results[:20]:\n",
    "#             file_names.append(str(res[0]) + '.jpg')\n",
    "\n",
    "#         # Write results to file\n",
    "#         writer.writerow([str(ind_outer) + '.txt',' '.join(file_names)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**:\n",
    "- Remove stop words\n",
    "- Remove stemming\n",
    "- Remove special characters \n",
    "- Lowercase everything\n",
    "- https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72\n",
    "\n",
    "**Postprocessing (?)**:\n",
    "- log-normalization\n",
    "- l1 normalization\n",
    "- l2 normalization\n",
    "- Standardize the data by subtracting the mean and dividing by the variance.\n",
    "\n",
    "**Clustering descriptions**:\n",
    "- Bag of words, 2-gram, maybe PCA\n",
    "- With BoW, use tf–idf\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://towardsdatascience.com/natural-language-processing-count-vectorization-with-scikit-learn-e7804269bb5e\n",
    "\n",
    "**Clustering images**:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "- Random Decision Forests\n",
    "- K-means or K-medoids\n",
    "- PCA is good for reducing noise, but the input data should be \"manifoldy\", we are probably dealing with \"clumpy\"\n",
    "- Niave bayes\n",
    "\n",
    "**CNN/RNN links**:\n",
    "- https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c\n",
    "- http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/\n",
    "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "- http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/\n",
    "- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "- https://medium.freecodecamp.org/learn-to-build-a-convolutional-neural-network-on-the-web-with-this-easy-tutorial-- 2d617ffeaef3\n",
    "- https://blog.insightdatascience.com/the-unreasonable-effectiveness-of-deep-learning-representations-4ce83fc663cf\n",
    "- https://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model\n",
    "- https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA set up:\n",
    "# pca = PCA(n_components=1100)\n",
    "# Y = np.array(list(train_df['final_train_features'].values), dtype=np.float)\n",
    "# X = pca.fit_transform(Y)\n",
    "# pca_final_train_features = X\n",
    "# for index in range(len(X)):\n",
    "#     train_df['pca_final_train_features'][index] = X[index]\n",
    "# train_df['pca_final_train_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
