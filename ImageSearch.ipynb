{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Challenge: Build a large-scale image search engine!\n",
    "\n",
    "You and your team of **three Cornell Tech students** are surely on the path to fame and fortune! You have been recruited by Google to disrupt Google Image Search by building a better search engine using novel statistical learning techniques.\n",
    "\n",
    "The specifications are simple: We need a way to **search for relevant images** given a natural language query. For instance, if a user types \"dog jumping to catch frisbee,\" your system will **rank-order the most relevant images** from a large database.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**During training**, you have a dataset of 10,000 samples. \n",
    "\n",
    "Each sample has the following data available for learning:\n",
    "- A 224x224 JPG image.\n",
    "- A list of tags indicating objects appeared in the image.\n",
    "- Feature vectors extracted using [Resnet](https://arxiv.org/abs/1512.03385), a state-of-the-art Deep-learned CNN (You don't have to train or run ResNet -- we are providing the features for you). See [here](http://ethereon.github.io/netscope/#/gist/b21e2aae116dc1ac7b50) for the illustration of the ResNet-101 architecture. The features are extracted from pool5 and fc1000 layer.\n",
    "- A five-sentence description, used to train your search engine.\n",
    "\n",
    "**During testing**, your system matches a single five-sentence description against a pool of 2,000 candidate samples from the test set. \n",
    "\n",
    "Each sample has:\n",
    "- A 224x224 JPEG image.\n",
    "- A list of tags for that image.\n",
    "- ResNet feature vectors for that image.\n",
    "\n",
    "**Output**:\n",
    "For each description, your system must rank-score each testing image with the likelihood of that image matches the given sentence. Your system then returns the name of the top 20 relevant images, delimited by space. See \"sample_submission.csv\" on the data page for more details on the output format.\n",
    "\n",
    "**Evaluation metric**:\n",
    "There are 2,000 descriptions, and for each description, you must compare against the entire 2,000-image test set. That is, rank-order test images for each test description. We will use **MAP@20** as the evaluation metric. If the corresponding image of a description is among your algorithm's 20 highest scoring images, this metric gives you a certain score based on the ranking of the corresponding image. Please refer to the evaluation page for more details. Use all of your skills, tools, and experience. It is OK to use libraries like numpy, scikit-learn, pandas, etc., as long as you cite them. Use cross-validation on training set to debug your algorithm. Submit your results to the Kaggle leaderboard and send your complete writeup to CMS. The data you use --- and the way you use the data --- is completely up to you.\n",
    "\n",
    "**Note**:\n",
    "The best teams of **three Cornell Tech students** might use visualization techniques for debugging (e.g., show top images retrieved by your algorithm and see whether they make sense or not), preprocessing, a nice way to compare tags and descriptions, leveraging visual features and combining them with tags and descriptions, supervised and/or unsupervised learning to best understand how to best take advantage of each data source available to them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File descriptions**:\n",
    "\n",
    "- images_train - 10,000 training images of size 224x224.\n",
    "- images_test - 2,000 test images of size 224x224.\n",
    "- tags_train - image tags correspond to training images. Each image have several tags indicating the human-labeled object categories appear in the image, in the form of \"supercategory:category\".\n",
    "- tags_test - image tags correspond to test images. Each image have several tags indicating the human-labeled object categories appear in the image, in the form of \"supercategory:category\".\n",
    "features_train - features extracted from a pre-trained Residual Network (ResNet) on training set, including 1,000 dimensional feature from classification layer (fc1000) and 2,048 dimensional feature from final convolution layer (pool5). Each dimension of the fc1000 feature corresponds to a WordNet synset here.\n",
    "- features_test - features extracted from the same Residual Network (ResNet) on test set, including 1,000 dimensional feature from classification layer (fc1000) and 2,048 dimensional feature from final convolution layer (pool5).\n",
    "- descriptions_train - image descriptions correspond to training images. Each image have 5 sentences for describing the image content.\n",
    "- descriptions_test - image descriptions for test images. Each image have 5 sentences for describing the image content. Notice that one test description corresponds to one test image. The task you need to do is to return top 20 images in test set for each test description.\n",
    "- sample_submission.csv - a sample submission file in the correct format.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Conor/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/Conor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.cm as cm\n",
    "from sklearn import cluster\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn import model_selection\n",
    "from scipy.spatial import distance\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.preprocessing import normalize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for training/testing data\n",
    "my_path = os.getcwd()\n",
    "tags_train_path = os.path.join(my_path, 'tags_train')\n",
    "tags_test_path  = os.path.join(my_path, 'tags_test')\n",
    "desc_train_path = os.path.join(my_path, 'descriptions_train')\n",
    "desc_test_path  = os.path.join(my_path, 'descriptions_test')\n",
    "image_train_path = os.path.join(my_path, 'images_train')\n",
    "image_test_path  = os.path.join(my_path, 'images_test')\n",
    "features_train_res_path = os.path.join(my_path, 'features_train/features_resnet1000_train.csv')\n",
    "features_test_res_path  = os.path.join(my_path, 'features_test/features_resnet1000_test.csv')\n",
    "features_train_res_int_path = os.path.join(my_path, 'features_train/features_resnet1000intermediate_train.csv')\n",
    "features_test_res_int_path  = os.path.join(my_path, 'features_test/features_resnet1000intermediate_test.csv')\n",
    "\n",
    "# Sort files in ascending order\n",
    "def order_keys(text):\n",
    "    return int(text.split('.')[0])\n",
    "\n",
    "# Read/return list of images within a folder\n",
    "def read_images(folder_path):\n",
    "    images = []\n",
    "    image_files = os.listdir(folder_path)\n",
    "    image_files.sort(key = order_keys)\n",
    "    for image_file in image_files:\n",
    "        # Open each image file\n",
    "        im = Image.open(os.path.join(folder_path, image_file), 'r')\n",
    "        # Convert to an np array\n",
    "        images.append(np.asarray(im))\n",
    "        # Close the file\n",
    "        im.close()\n",
    "    return images\n",
    "\n",
    "# Read/return lists of elements from files within a folder\n",
    "def read_files(folder_path):\n",
    "    elements = []\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key = order_keys)\n",
    "    for f in files:\n",
    "        # Open each text file. Strip leading/trailing whitespace\n",
    "        lines = [line.strip() for line in open(os.path.join(folder_path, f))]\n",
    "        elements.append(' '.join(lines))\n",
    "    return elements\n",
    "\n",
    "# Read/return list of features\n",
    "def read_features(file_path):\n",
    "    reader = csv.reader(open(file_path), delimiter=\",\")\n",
    "    features = sorted(reader, key = lambda row: int(row[0].split('/')[1].split('.')[0]))\n",
    "    # Skip the image name\n",
    "    for ind, image in enumerate(features):\n",
    "        feats = [float(i) for i in image[1:]]\n",
    "        features[ind] = np.array(feats, dtype=float)\n",
    "    return features\n",
    "\n",
    "# Print random rows from a dataframe\n",
    "def aux_print_1(df, num_rows):    \n",
    "    for index in range(num_rows):\n",
    "        rand_index = random.randrange(0, len(df.index))\n",
    "        row = df.iloc[rand_index]\n",
    "        print \"Image num. {}\".format(rand_index)\n",
    "        plt.imshow(row['image'])\n",
    "        plt.show()\n",
    "        print row['tag']\n",
    "        print row['description']\n",
    "        print row['resnet_feats'][:10]\n",
    "        print row['resnet_feats_int'][:10]\n",
    "\n",
    "# Print random rows from a dataframe\n",
    "def aux_print_2(df, num_rows):    \n",
    "    for index in range(num_rows):\n",
    "        rand_index = random.randrange(0, len(df.index))\n",
    "        row = df.iloc[rand_index]\n",
    "        print \"Image num. {}\".format(rand_index)\n",
    "        plt.imshow(row['image'])\n",
    "        plt.show()\n",
    "        print row['tag']\n",
    "        print row['description']\n",
    "        print row['resnet_feats'][:10]\n",
    "        print row['resnet_feats_int'][:10]\n",
    "        print zip(row['description_vectors'], vectorizer.get_feature_names())\n",
    "\n",
    "# Transform input to lowercase\n",
    "def to_lowercase(sent):\n",
    "    return sent.lower()\n",
    "\n",
    "# Lemmatize input\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(sent):\n",
    "    words = sent.split(' ')\n",
    "    # Lemmatize as verbs\n",
    "    # lemmed_words = [lemmatizer.lemmatize(word, 'v') for word in words]\n",
    "    lemmed_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmed_words)\n",
    "\n",
    "# Stem input\n",
    "stemmer = SnowballStemmer('english')\n",
    "def stem(sent):\n",
    "    words = sent.split(' ')\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "    \n",
    "# Remove stop words from input\n",
    "def remove_stopwords(sent):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = sent.split(' ')\n",
    "    unstopped_words = [word for word in words if not word in stops]\n",
    "    return ' '.join(unstopped_words)\n",
    "\n",
    "# Remove special characters from input\n",
    "def remove_special_chars(sent):\n",
    "    unspecial_words = []\n",
    "    words = sent.split(' ')\n",
    "    for word in words:\n",
    "        unspecial_word = ''.join(char for char in word if char.isalnum())\n",
    "        unspecial_words.append(unspecial_word)\n",
    "    return ' '.join(unspecial_words)\n",
    "\n",
    "# Fit/transform with count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "def count_vectorize(corpus):\n",
    "    features = []\n",
    "    count_vects = vectorizer.fit_transform(corpus)\n",
    "    count_vects = count_vects.toarray()\n",
    "    for vects in count_vects:\n",
    "        counts = [float(i) for i in vects]\n",
    "        features.append(np.array(counts, dtype=float))\n",
    "    return features\n",
    "\n",
    "# Normalize with l2 on vectorized input\n",
    "def get_norm(sent):\n",
    "    return np.divide(sent, np.linalg.norm(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the training data\n",
    "train_df = pd.DataFrame()\n",
    "train_df['tag'] = read_files(tags_train_path)[:1000]\n",
    "train_df['image'] = read_images(image_train_path)[:1000]\n",
    "train_df['description'] = read_files(desc_train_path)[:1000]\n",
    "train_df['resnet_feats'] = read_features(features_train_res_path)[:1000]\n",
    "train_df['resnet_feats_int'] = read_features(features_train_res_int_path)[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training data\n",
    "for index, desc in enumerate(train_df['description']):\n",
    "    desc = to_lowercase(desc)\n",
    "    desc = remove_special_chars(desc)\n",
    "    desc = remove_stopwords(desc)\n",
    "    desc = lemmatize(desc)\n",
    "    # desc = stem(desc)\n",
    "    train_df['description'][index] = desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorize the data\n",
    "train_df['description_vectors'] = count_vectorize(train_df['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the vectorized data\n",
    "for index, desc in enumerate(train_df['description_vectors']):\n",
    "    desc = get_norm(desc)\n",
    "    train_df['description_vectors'][index] = desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge resnet_feats with images to create our feature vectors\n",
    "train_df['final_train_features'] = \"\"\n",
    "for index in range(len(train_df['resnet_feats'])):\n",
    "    train_df['final_train_features'][index] = np.append(train_df['resnet_feats'][index], train_df['description_vectors'][index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format the training data. \n",
    "# We will combine each resnet feature vector with the correct corresponding normalized vector count\n",
    "# and label that as 1. We will then combine the same resnet feature vector with a different normalized\n",
    "# vector count and label that as 0. In this way, we are providing the NN with what we consider to be \n",
    "# correct (1) or incorrect (0) values. For each resent feature vector, we will provide 1 correct and\n",
    "# 2 incorrect values.\n",
    "X_training_vals   = []\n",
    "X_training_labels = []\n",
    "for ind_out, img_feat in enumerate(train_df['resnet_feats']):\n",
    "    # Get euclidean distance between chosen resnet feature with all\n",
    "    # other resnet features\n",
    "    dist = []\n",
    "    for ind_in, comp_img_feat in enumerate(train_df['resnet_feats']):\n",
    "        euc_dist = distance.euclidean(img_feat, comp_img_feat)\n",
    "        dist.append((ind_in, euc_dist))\n",
    "    dist.sort()\n",
    "\n",
    "    # Add the correct resnet feature vector and vector count\n",
    "    X_training_vals.append(np.append(img_feat, train_df['description_vectors'][ind_out]))\n",
    "    X_training_labels.append(1)\n",
    "    \n",
    "    # Add the incorrect resnet feature vector and vector count\n",
    "    ind = dist.pop()[0]\n",
    "    X_training_vals.append(np.append(train_df['resnet_feats'][ind], train_df['description_vectors'][ind]))\n",
    "    X_training_labels.append(0)\n",
    "    ind = dist.pop()[0]\n",
    "    X_training_vals.append(np.append(train_df['resnet_feats'][ind], train_df['description_vectors'][ind]))\n",
    "    X_training_labels.append(0)                           \n",
    "\n",
    "X_train = pd.DataFrame(X_training_vals, X_training_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the testing data\n",
    "test_df = pd.DataFrame()\n",
    "test_df['tag'] = read_files(tags_test_path)\n",
    "test_df['image'] = read_images(image_test_path)\n",
    "test_df['description'] = read_files(desc_test_path)\n",
    "test_df['resnet_feats'] = read_features(features_test_res_path)\n",
    "test_df['resnet_feats_int'] = read_features(features_test_res_int_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the testing data\n",
    "for index, desc in enumerate(test_df['description']):\n",
    "    desc = to_lowercase(desc)\n",
    "    desc = remove_special_chars(desc)\n",
    "    desc = remove_stopwords(desc)\n",
    "    desc = lemmatize(desc)\n",
    "    desc = stem(desc)\n",
    "    test_df['description'][index] = desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output results to CSV\n",
    "\n",
    "# with open('test_results.csv', 'w') as csvfile:\n",
    "#     writer = csv.writer(csvfile, delimiter=',')\n",
    "#     writer.writerow(['Description_ID','Top_20_Image_IDs'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Clustering is useful when data is clumpy. (K-means)\n",
    "\n",
    "# Random Decision Forests (also called Random Forests) were first proposed as a technique for handwritten digit classification.\n",
    "# - Might want to get misclassification error, Gini index, cross-entropy/deviance from trees\n",
    "\n",
    "# K-Medoids is when we don't have access to the vector space from which dissimilarities where generated. \n",
    "\n",
    "# PCA will give a dimensionality reduced approximated representation. It can help in denoising the data. But it is useful for manifoldy data, and will not benefit us. \n",
    "\n",
    "# Could use Niave Bayes with BoW, where the bag has normalized frequencies. \n",
    "\n",
    "# Preprocessing the desciption vectors:\n",
    "# - Lowercase all\n",
    "# - Remove punctuation\n",
    "# - Vectorize a text corpus\n",
    "#   - Coefficient could be binary, based on word count, based on tf-idf\n",
    "#   - https://keras.io/preprocessing/text/\n",
    "# - Try lematize, stemming, to show results\n",
    "#   - Check: https://www.kaggle.com/lystdo/lstm-with-word2vec-embeddings\n",
    "\n",
    "# Read this about which layers to use: https://arxiv.org/pdf/1512.03385.pdf\n",
    "\n",
    "\n",
    "# TFID\n",
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**:\n",
    "- Remove stop words\n",
    "- Remove stemming\n",
    "- Remove special characters \n",
    "- Lowercase everything\n",
    "- https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72\n",
    "\n",
    "**Postprocessing (?)**:\n",
    "- log-normalization\n",
    "- l1 normalization\n",
    "- l2 normalization\n",
    "- Standardize the data by subtracting the mean and dividing by the variance.\n",
    "\n",
    "**Clustering descriptions**:\n",
    "- Bag of words, 2-gram, maybe PCA\n",
    "- With BoW, use tf–idf\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://towardsdatascience.com/natural-language-processing-count-vectorization-with-scikit-learn-e7804269bb5e\n",
    "\n",
    "**Clustering images**:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "- Random Decision Forests\n",
    "- K-means or K-medoids\n",
    "- PCA is good for reducing noise, but the input data should be \"manifoldy\", we are probably dealing with \"clumpy\"\n",
    "- Niave bayes\n",
    "\n",
    "**CNN/RNN links**:\n",
    "- https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c\n",
    "- http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/\n",
    "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "- http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/\n",
    "- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "- https://medium.freecodecamp.org/learn-to-build-a-convolutional-neural-network-on-the-web-with-this-easy-tutorial-- 2d617ffeaef3\n",
    "- https://blog.insightdatascience.com/the-unreasonable-effectiveness-of-deep-learning-representations-4ce83fc663cf\n",
    "- https://papers.nips.cc/paper/5204-devise-a-deep-visual-semantic-embedding-model\n",
    "- https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
